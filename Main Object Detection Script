# OBJECT DETECTION 

#                               IMPORTED DOCUMENTS 
# 'coco.names'                List of typical object used in a typical object detection code
# 'weightsPath.pb'            Weights given to each of the objects from 'coco.names'
# 'configurationPath.pbtxt'   The configuration path of the objects found in the 'coco.names' list

import cv2
import numpy as np
from cv2 import VideoCapture

thresh = 0.1        # Object must have at least this confidence level to be detected 
nms_threshold = 0.5 # The lower it is the more NMS suppression occurs. 1 => Dont Supress anything. 0 => Supress everything. 

cap = cv2.VideoCapture(0)                          # => Captures images from my webcam 

# --------------------------------------------------RESCALE----------------------------------------------------------------
def rescaleFrame (frame, scale = 1.0):  # Function takes in a frame and rescales it by the scale value (CURRENTLY SET TO: 25%)
    width = int(frame.shape[1] * scale)  # 'frame.shape[1]' returns the width of the image & int(frame.shape[1]) makes the width an integer
    height = int(frame.shape[0] * scale) # 'frame.shape[0]' returns the height of the image & int(frame.shape[0]) makes the height an integer
    dimensions = (width,height)          # varible storing width and height 

    return cv2.resize(frame, dimensions,interpolation=cv2.INTER_AREA) # We will talk about this later in depth but for now just know
                                                                    # it resizes the frame to a specific dimension
# -----------------------------------------------------------------------------------------------------------------------


# Bottom two lines change width(3) and height(4) of image
cap.set(3,640) 
cap.set(4,480)

className = []                                     # => Making an empty array
classFile = 'coco.names'                           # => Variable containing the contains of the named file or printout the names and paste it in the variable
with open(classFile, 'rt') as f:                   # => Opening the coco.names file (List of names specifically for Object Dection)
    className = f.read().rstrip('\n').split('\n')  # => defining 'className'(1)Reading coco.names, (2)Removing trailing char '\n'  
                                                   #   of words, (3)Than spliting the string of words at every '\n' left   
# print(className)                                 # => Left with an array of all the names within 'coco.names'

configPath     = 'configurationPath.pbtxt'         # => Variable containing the contains of the named file
weightsPath    = 'weightsPath.pb'                  # => Variable containing the contains of the named file

net = cv2.dnn_DetectionModel(weightsPath,configPath)             # => Function is provided by openCV that does all the object 
                                                                 #    detection processes for us. We just need to provide the
                                                                 #    function with the weigths and configuration path which 
                                                                 #    we just downloaded from the OpenCV website  

# Following the Parameters set by document found containing the weights and configuration paths
net.setInputSize(320,320) 
net.setInputScale(1.0/127.5)
net.setInputMean((127.5,127.5,127.5)) 
net.setInputSwapRB(True)

while True: 

    success, img = cap.read()    # => Reads the images from my webcam 
    # => classIds, confs, bbox: All values outputted by the object detection model/function OpenCV provides us 
    # => classIds = List of ids of the objects that were detected in the image 
    # => Confs = List of confidence levels of those objects detected
    # => bbox = List of 4 value coordinates of each of those objects (bounding box)

    # --------------------------------------------------RESCALE----------------------------------------------------------------
    img = rescaleFrame(img) # Using the rescale function I made 
     # ------------------------------------------------------------------------------------------------------------------------

    classIds, confs, bbox =  net.detect(img,confThreshold = thresh) # =>'net.detect' detects the chosen image and tries to output 
                                                                #    the closest fit from the 'coco.names' list 
                                                                # => 'confThreshold = 0.5' is a minimum confidence level that must 
                                                                #    be returned for  

    
    # #--------------------------------------------------------NON MAX SUPRESSION (VERSION 2)----------------------------------------------------------------------------
    bbox = list(bbox) #NMS needs the bbox to be a list not a numpy array
    confs = list(np.array(confs).reshape(1,-1)[0])   #reshape(1,-1)[0]    removes the first character and the last two characters of the array then convert it to a list 
                                           #                    as the NMS function needs a list 
    confs = list(map(float,confs))         # Maps the values as only floats 

    indices = cv2.dnn.NMSBoxes(bbox, confs, thresh,nms_threshold) 
    # Non maximum supression: supressions the lower threshold detection of an object if a higher threshold detection has already identified that same object
    # so it cuts out repeated data (clean data)
    # 'cv2.dnn.NMSBoxes(ALL COORDINATES, ALL CONFS LEVELS, Threshold, )

    if((len(classIds) != 0)):
        for i in indices: 
            if(classIds[i] == 37):
                i = i[0]
                box = bbox[i]
                x,y,w,h = box[0], box[1], box[2], box[3]

                #------------------------------------------DISTANCE---------------------------------------------------------------------------------------

                total_width  =  int(img.shape[1])  # 'frame.shape[1]' returns the width of the image & int(frame.shape[1]) makes the width an integer
                total_height =  int(img.shape[0])  # 'frame.shape[0]' returns the height of the image & int(frame.shape[0]) makes the height an integer
                    
                total_area   =  total_height * total_width

                if(h >= w):
                   w = h 
                else:
                   h = w
                
                ball_area    =  h * w  
                ball_coverage = ball_area / total_area 
                ball_coverage = ball_coverage * 10000

                distance = 500 / pow(ball_coverage,0.595) # Inches
                #------------------------------------------------------------------------------------------------------------------------------------

                cv2.rectangle(img,(x,y),(x+w,h+y),color=(0,255,0),thickness = 1)
                cv2.putText(img,className[classIds[i][0] - 1].upper(), (box[0],box[1]+50), cv2.FONT_HERSHEY_COMPLEX,1, (0,255,0), thickness = 2)
                cv2.putText(img,str(round(confs[i]*100,2)), (box[0]+100,box[1]+50), cv2.FONT_HERSHEY_COMPLEX,1, (255,0,0), thickness = 2)
                cv2.putText(img,str(round(distance)), (box[0]+200,box[1]+50), cv2.FONT_HERSHEY_COMPLEX,1, (0,0,255), thickness = 2) 

    cv2.imshow("Ouput", img)

    if (cv2.waitKey(1) & 0xFF == ord('q')):   # Breaks out of the while loop once the user inputs 'q'
        break
   #---------------------------------------------------------------------END-----------------------------------------------------------------------
   






   #-------------------------------------------------------NORMAL (VERSION 1)---------------------------------------------------------------------------
    # if ((len(classIds) != 0)):                                      # => Only goes thru if something is detected
    #     # => 'Zip' combines multiple lists into one list. Each variable in that single list is made up of the values from 
    #     #    those seperate lists. (e.g. (1, 49, [32,45,65,78]) would be a single variable)) this is done for the purposes of
    #     #    having only a single for loop with all the necessary values instead of one for loop for each list. 
    #     # => '.flatten()' has to be used to all the lists if you want to zip them 
    #     # => ClassId, confidence, box are placeholder variables for the values of each of the objects going through the forloop 
       
    #     for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), bbox): 

    #         if (classId == 37):

    #             #------------------------------------------DISTANCE---------------------------------------------------------------------------------------
    #             # x => box[0], y => box[1], w => box[2], h => box[3]
    #             x = box[0]
    #             y = box[1]
    #             w = box[2] 
    #             h = box[3]

    #             total_width  =  int(img.shape[1])  # 'frame.shape[1]' returns the width of the image & int(frame.shape[1]) makes the width an integer
    #             total_height =  int(img.shape[0])  # 'frame.shape[0]' returns the height of the image & int(frame.shape[0]) makes the height an integer
                    
    #             total_area   =  total_height * total_width

    #             if(h >= w):
    #                w = h 
    #             else:
    #                h = w
                
    #             ball_area    =  h * w  
    #             ball_coverage = ball_area / total_area 
    #             ball_coverage = ball_coverage * 10000

    #             distance = 500 / pow(ball_coverage,0.595) # Inches
    #             #------------------------------------------------------------------------------------------------------------------------------------

    #             cv2.rectangle(img,box,color=(0,255,0),thickness = 1)
    #             cv2.putText(img,className[classId - 1].upper(), (box[0],box[1]+50), cv2.FONT_HERSHEY_COMPLEX,1, (0,255,0), thickness = 2)
    #             cv2.putText(img,str(round(confidence*100,2)), (box[0]+100,box[1]+50), cv2.FONT_HERSHEY_COMPLEX,1, (255,0,0), thickness = 2)
    #             cv2.putText(img,str(round(distance)), (box[0]+200,box[1]+50), cv2.FONT_HERSHEY_COMPLEX,1, (0,0,255), thickness = 2) # Inches
    #
    # cv2.imshow("Ouput", img)

    # if (cv2.waitKey(1) & 0xFF == ord('q')):   # Breaks out of the while loop once the user inputs 'q'
    #     break
    #--------------------------------------------------------------------------------------------------------------------------------------------------
